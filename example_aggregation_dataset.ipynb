{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install DenMune clustering algorithm using pip command from the offecial Python repository, PyPi\n",
    "# from https://pypi.org/project/denmune/\n",
    "!pip install denmune\n",
    "\n",
    "# now import it\n",
    "from denmune.denmune import DenMune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'aggregation' # let us take Aggregation dataset as an example\n",
    "\n",
    "url = \"https://zerobytes.one/denmune_data/\"\n",
    "file_ext = \".txt\"\n",
    "ground_ext = \"-gt\"\n",
    "\n",
    "dataset_url = url + dataset + file_ext\n",
    "groundtruth_url = url + dataset + ground_ext  + file_ext\n",
    "\n",
    "data_path = 'data/' # change it to whatever you put your data, set it to ''; so it will retrive from current folder\n",
    "if  not os.path.isfile(data_path + dataset + file_ext):\n",
    "    req = requests.get(dataset_url)\n",
    "    with open(data_path + dataset + file_ext, 'wb') as f:\n",
    "        f.write(req.content)\n",
    "        \n",
    "if  not os.path.isfile(data_path + dataset + ground_ext + file_ext):\n",
    "    req = requests.get(groundtruth_url)\n",
    "    with open(data_path + dataset +  ground_ext + file_ext, 'wb') as f:\n",
    "        f.write(req.content)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denmune's Paramaters\n",
    "# DenMune(dataset=dataset, k_nearest=n, data_path=data_path, verpose=verpose_mode, show_plot=show_plot, show_noise=show_noise)\n",
    "verpose_mode = True # view in-depth analysis of time complexity and outlier detection, num of clusters\n",
    "show_plot = True  # show plots on/off\n",
    "show_noise = True # show noise and outlier on/off\n",
    "\n",
    "# loop's parameters\n",
    "start = 1\n",
    "step = 1\n",
    "end=15\n",
    "\n",
    "# Validity indexes' parameters\n",
    "validity_val = -1\n",
    "best_k = 0\n",
    "best_val = -1\n",
    "\n",
    "validity_idx = 2 # Acc=1, F1-score=2,  NMI=3, AMI=4, ARI=5,  Homogeneity=6, and Completeness=7\n",
    "df = pd.DataFrame(columns =['K', 'ACC', 'F1', 'NMI', 'AMI', 'ARI','Homogeneity', 'Completeness', 'Time' ])\n",
    "\n",
    "\n",
    "for n in range(start, end+1, step):\n",
    "    start_time = time.time()\n",
    "    dm = DenMune(dataset=dataset, k_nearest=n, data_path=data_path, verpose=verpose_mode, show_noise=show_noise)\n",
    "    labels_true, labels_pred = dm.output_Clusters()\n",
    "    if show_plot == True and n==start:\n",
    "        # Let us plot the groundtruth of this dataset which is reduced to 2-d using t-SNE\n",
    "        print (\"Dataset\\'s Groundtruht\")\n",
    "        dm.plot_clusters(labels_true, ground=True)\n",
    "        print('\\n', \"=====\" * 20 , '\\n')       \n",
    "               \n",
    "    end_time = time.time()\n",
    "    \n",
    "    validity_indexes = dm.validate_Clusters(labels_true, labels_pred)\n",
    "    validity_val = validity_indexes[validity_idx]\n",
    "    validity_indexes[0] = n\n",
    "    validity_indexes[8] = end_time - start_time\n",
    "    \n",
    "    df = df.append(pd.Series(validity_indexes, index=df.columns ), ignore_index=True)\n",
    "    \n",
    "    if (best_val < validity_val):\n",
    "        best_val = validity_val\n",
    "        best_k = n\n",
    "        # Let us show results where only an improve in accuracy is detected\n",
    "        if show_plot:\n",
    "            dm.plot_clusters(labels_pred, show_noise=show_noise)\n",
    "    print ('k=' , n, ':Validity score is:', validity_val , 'but best score is', best_val, 'at k=', best_k , end='     ')\n",
    "            \n",
    "    if not verpose_mode:\n",
    "        print('\\r', end='')\n",
    "    else:\n",
    "        print('\\n', \"=====\" * 20 , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is time to save the results\n",
    "results_path = 'results/'  # change it to whatever you output results to, set it to ''; so it will output to current folder\n",
    "para_file = 'denmune'+ '_para_'  + dataset + '.csv'\n",
    "df.sort_values(by=['F1', 'NMI', 'ARI'] , ascending=False, inplace=True)   \n",
    "df.to_csv(results_path + para_file, index=False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # it is sorted now and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
